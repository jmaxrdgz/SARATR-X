{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# SARATR-X Training Experiments on Google Colab\n",
    "\n",
    "This notebook trains the SARATR-X model with MAE-HiViT tiny backbone using 4 different reconstruction techniques:\n",
    "1. **Pixel-reconstruction**: SAR → SAR reconstruction\n",
    "2. **MGF-reconstruction**: SAR → Multi-scale Gradient Features\n",
    "3. **RGB-reconstruction**: SAR → RGB optical images\n",
    "4. **Greyscale-reconstruction**: SAR → Greyscale optical images\n",
    "\n",
    "## Important Notes:\n",
    "- **GPU**: Optimized for T4 GPU (free tier)\n",
    "- **Runtime**: Free tier has ~1.5 hour limit - checkpoints saved to Google Drive\n",
    "- **Dataset**: Sentinel-1 & Sentinel-2 from Kaggle\n",
    "- **Storage**: All results saved to Google Drive (persists after session ends)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1. Setup: Mount Google Drive for Persistent Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount-drive"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create directories for experiments\n",
    "import os\n",
    "os.makedirs('/content/drive/MyDrive/SARATRX_experiments', exist_ok=True)\n",
    "os.makedirs('/content/drive/MyDrive/SARATRX_experiments/checkpoints', exist_ok=True)\n",
    "os.makedirs('/content/drive/MyDrive/SARATRX_experiments/logs', exist_ok=True)\n",
    "\n",
    "print(\"✓ Google Drive mounted successfully\")\n",
    "print(\"✓ Experiment directories created in: /content/drive/MyDrive/SARATRX_experiments/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "check-gpu"
   },
   "source": [
    "## 2. Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gpu-check"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "import torch\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clone-repo"
   },
   "source": [
    "## 3. Clone Repository and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone"
   },
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/jmaxrdgz/SARATR-X.git\n",
    "%cd SARATR-X\n",
    "\n",
    "print(\"\\n✓ Repository cloned successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-deps"
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q -r requirements.txt\n",
    "!pip install -q 'urllib3<2.0' kaggle  # For Kaggle dataset download\n",
    "\n",
    "print(\"\\n✓ Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download-pretrained"
   },
   "source": [
    "## 4. Download Pretrained Weights\n",
    "\n",
    "Download MAE-HiViT pretrained weights for initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pretrained-weights"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('checkpoints', exist_ok=True)\n",
    "\n",
    "# Download pretrained MAE-HiViT weights\n",
    "# Note: Update this URL with the actual location of pretrained weights\n",
    "!wget -O checkpoints/mae_hivit_base_1600ep.pth https://github.com/zhangxiaosong18/hivit/releases/download/v1.0/mae_hivit_base_1600ep.pth\n",
    "\n",
    "print(\"\\n✓ Pretrained weights downloaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kaggle-setup"
   },
   "source": [
    "## 5. Setup Kaggle Credentials\n",
    "\n",
    "To download the Sentinel dataset:\n",
    "1. Go to https://www.kaggle.com/account\n",
    "2. Scroll to \"API\" section\n",
    "3. Click \"Create New API Token\" to download `kaggle.json`\n",
    "4. Upload it in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kaggle-creds"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "print(\"Please upload your kaggle.json file:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Setup Kaggle credentials\n",
    "os.makedirs('/root/.kaggle', exist_ok=True)\n",
    "!cp kaggle.json /root/.kaggle/\n",
    "!chmod 600 /root/.kaggle/kaggle.json\n",
    "\n",
    "print(\"\\n✓ Kaggle credentials configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download-dataset"
   },
   "source": [
    "## 6. Download Sentinel-1 & Sentinel-2 Dataset from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download-sentinel"
   },
   "outputs": [],
   "source": [
    "import kaggle\n",
    "import os\n",
    "\n",
    "# Create dataset directory\n",
    "os.makedirs('dataset/sentinel12', exist_ok=True)\n",
    "\n",
    "# Download the dataset\n",
    "dataset_name = 'requiemonk/sentinel12-image-pairs-segregated-by-terrain'\n",
    "print(f\"Downloading {dataset_name}...\")\n",
    "print(\"This may take 5-10 minutes...\\n\")\n",
    "\n",
    "kaggle.api.dataset_download_files(\n",
    "    dataset_name,\n",
    "    path='dataset/sentinel12',\n",
    "    unzip=True\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Dataset downloaded successfully\")\n",
    "\n",
    "# Check dataset structure\n",
    "!ls -lh dataset/sentinel12/v_2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "preprocess-data"
   },
   "source": [
    "## 7. Preprocess Dataset: Convert PNG to NPY\n",
    "\n",
    "The model expects `.npy` files but Kaggle provides PNG images. We'll convert them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "convert-png-npy"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "def convert_png_to_npy(data_path):\n",
    "    \"\"\"Convert PNG images to NPY format for faster loading.\"\"\"\n",
    "    data_path = Path(data_path)\n",
    "    \n",
    "    # Find all terrain directories\n",
    "    terrain_dirs = [d for d in data_path.iterdir() if d.is_dir()]\n",
    "    \n",
    "    total_converted = 0\n",
    "    \n",
    "    for terrain in tqdm(terrain_dirs, desc=\"Processing terrains\"):\n",
    "        # Process S1 (SAR) images\n",
    "        s1_dir = terrain / \"s1\"\n",
    "        if s1_dir.exists():\n",
    "            for img_file in s1_dir.glob(\"*.png\"):\n",
    "                npy_file = img_file.with_suffix('.npy')\n",
    "                if not npy_file.exists():\n",
    "                    img = np.array(Image.open(img_file)).astype(np.float32) / 255.0\n",
    "                    np.save(npy_file, img)\n",
    "                    total_converted += 1\n",
    "        \n",
    "        # Process S2 (Optical) images\n",
    "        s2_dir = terrain / \"s2\"\n",
    "        if s2_dir.exists():\n",
    "            for img_file in s2_dir.glob(\"*.png\"):\n",
    "                npy_file = img_file.with_suffix('.npy')\n",
    "                if not npy_file.exists():\n",
    "                    img = np.array(Image.open(img_file)).astype(np.float32) / 255.0\n",
    "                    np.save(npy_file, img)\n",
    "                    total_converted += 1\n",
    "    \n",
    "    return total_converted\n",
    "\n",
    "# Convert images\n",
    "print(\"Converting PNG images to NPY format...\")\n",
    "num_converted = convert_png_to_npy('dataset/sentinel12/v_2')\n",
    "print(f\"\\n✓ Converted {num_converted} images to NPY format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "verify-dataset"
   },
   "source": [
    "## 8. Verify Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "verify"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path('dataset/sentinel12/v_2/')\n",
    "\n",
    "# Find sample images\n",
    "terrain_dirs = [d for d in data_path.iterdir() if d.is_dir()]\n",
    "sample_terrain = terrain_dirs[0]\n",
    "\n",
    "sar_files = list((sample_terrain / \"s1\").glob(\"*.npy\"))\n",
    "opt_files = list((sample_terrain / \"s2\").glob(\"*.npy\"))\n",
    "\n",
    "print(f\"Dataset statistics:\")\n",
    "print(f\"  - Terrain types: {len(terrain_dirs)}\")\n",
    "print(f\"  - SAR images: {len(sar_files)} in {sample_terrain.name}\")\n",
    "print(f\"  - Optical images: {len(opt_files)} in {sample_terrain.name}\")\n",
    "\n",
    "# Visualize samples\n",
    "if sar_files and opt_files:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "    \n",
    "    for i in range(2):\n",
    "        sar_img = np.load(sar_files[i])\n",
    "        opt_img = np.load(opt_files[i])\n",
    "        \n",
    "        axes[i, 0].imshow(sar_img)\n",
    "        axes[i, 0].set_title(f'SAR: {sar_files[i].name}')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        axes[i, 1].imshow(opt_img)\n",
    "        axes[i, 1].set_title(f'Optical: {opt_files[i].name}')\n",
    "        axes[i, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nImage shapes: SAR={sar_img.shape}, Optical={opt_img.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create-configs"
   },
   "source": [
    "## 9. Create Experiment Configurations\n",
    "\n",
    "We'll create 4 different configurations for our experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "configs"
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "\n",
    "# Base configuration for T4 GPU and free tier constraints\n",
    "base_config = {\n",
    "    'model': {\n",
    "        'name': 'SARATRX',\n",
    "        'in_chans': 3,\n",
    "        'mgf_kens': [9, 13, 17],\n",
    "        'resume': None,\n",
    "        'norm_pix_loss': False\n",
    "    },\n",
    "    'data': {\n",
    "        'dataset_name': 'sentinel',\n",
    "        'train_data': 'dataset/sentinel12/v_2',\n",
    "        'img_size': 256,\n",
    "        'dataset_std_dev': 1.57,\n",
    "        'num_workers': 2  # Reduced for Colab\n",
    "    },\n",
    "    'train': {\n",
    "        'init_weights': 'checkpoints/mae_hivit_base_1600ep.pth',\n",
    "        'seed': 42,\n",
    "        'n_gpu': 'auto',\n",
    "        'epochs': 50,  # Reduced for T4 GPU time constraints\n",
    "        'warmup_epochs': 5,\n",
    "        'batch_size': 32,  # Reduced from 64 for T4 GPU memory\n",
    "        'lr': 1.5e-4,\n",
    "        'weight_decay': 0.05,\n",
    "        'optimizer_momentum': {\n",
    "            'beta1': 0.9,\n",
    "            'beta2': 0.95\n",
    "        },\n",
    "        'clip_grad': 5.0\n",
    "    }\n",
    "}\n",
    "\n",
    "# Experiment 1: Pixel-reconstruction SAR-to-SAR\n",
    "exp1_config = base_config.copy()\n",
    "exp1_config['model'] = base_config['model'].copy()\n",
    "exp1_config['model']['target_mode'] = 'optical'  # Will use SAR as both input/target\n",
    "exp1_config['experiment_name'] = 'exp1_pixel_sar'\n",
    "\n",
    "# Experiment 2: MGF-reconstruction SAR\n",
    "exp2_config = base_config.copy()\n",
    "exp2_config['model'] = base_config['model'].copy()\n",
    "exp2_config['model']['target_mode'] = 'mgf'\n",
    "exp2_config['experiment_name'] = 'exp2_mgf_sar'\n",
    "\n",
    "# Experiment 3: RGB-reconstruction SAR-to-RGB\n",
    "exp3_config = base_config.copy()\n",
    "exp3_config['model'] = base_config['model'].copy()\n",
    "exp3_config['model']['target_mode'] = 'optical'\n",
    "exp3_config['experiment_name'] = 'exp3_rgb_sar_to_rgb'\n",
    "\n",
    "# Experiment 4: Greyscale-reconstruction SAR-to-Greyscale\n",
    "exp4_config = base_config.copy()\n",
    "exp4_config['model'] = base_config['model'].copy()\n",
    "exp4_config['model']['target_mode'] = 'optical'  # Will convert optical to greyscale\n",
    "exp4_config['experiment_name'] = 'exp4_grey_sar_to_grey'\n",
    "exp4_config['data'] = base_config['data'].copy()\n",
    "exp4_config['data']['greyscale_target'] = True  # Custom flag\n",
    "\n",
    "# Save configurations\n",
    "os.makedirs('config/experiments', exist_ok=True)\n",
    "\n",
    "configs = {\n",
    "    'exp1_pixel_sar.yaml': exp1_config,\n",
    "    'exp2_mgf_sar.yaml': exp2_config,\n",
    "    'exp3_rgb_sar_to_rgb.yaml': exp3_config,\n",
    "    'exp4_grey_sar_to_grey.yaml': exp4_config\n",
    "}\n",
    "\n",
    "for filename, config in configs.items():\n",
    "    with open(f'config/experiments/{filename}', 'w') as f:\n",
    "        yaml.dump(config, f, default_flow_style=False)\n",
    "\n",
    "print(\"✓ Created 4 experiment configurations:\")\n",
    "for filename in configs.keys():\n",
    "    print(f\"  - {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "modify-code"
   },
   "source": [
    "## 10. Create Custom Training Scripts for Experiments\n",
    "\n",
    "We need custom scripts to handle the different reconstruction targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training-scripts"
   },
   "outputs": [],
   "source": [
    "%%writefile train_experiments.py\n",
    "\"\"\"Custom training script for SARATR-X experiments.\"\"\"\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import torch\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "# Import SARATR-X modules\n",
    "from model.saratrx import SARATRX\n",
    "from data.data_pretrain import build_loader\n",
    "import config as config_module\n",
    "\n",
    "def load_config(config_path):\n",
    "    \"\"\"Load configuration from YAML file.\"\"\"\n",
    "    with open(config_path, 'r') as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "    \n",
    "    # Update the global config object\n",
    "    for key, value in cfg.items():\n",
    "        if hasattr(config_module.config, key):\n",
    "            if isinstance(value, dict):\n",
    "                for subkey, subvalue in value.items():\n",
    "                    setattr(getattr(config_module.config, key), subkey, subvalue)\n",
    "            else:\n",
    "                setattr(config_module.config, key, value)\n",
    "    \n",
    "    return cfg\n",
    "\n",
    "def train_experiment(config_path, checkpoint_dir, log_dir):\n",
    "    \"\"\"Train a single experiment.\"\"\"\n",
    "    # Load configuration\n",
    "    cfg = load_config(config_path)\n",
    "    exp_name = cfg.get('experiment_name', 'experiment')\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Starting Experiment: {exp_name}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Build data loader\n",
    "    print(\"Building data loader...\")\n",
    "    \n",
    "    # Handle special case for SAR-to-SAR (Experiment 1)\n",
    "    if exp_name == 'exp1_pixel_sar':\n",
    "        # For pixel SAR reconstruction, we use SAR as both input and target\n",
    "        # We'll modify the dataset to return SAR twice\n",
    "        from data.dataset_sentinel import SentinelDataset\n",
    "        from data.data_pretrain import PairedTransform\n",
    "        from torchvision import transforms\n",
    "        from torch.utils.data import DataLoader\n",
    "        \n",
    "        class SARtoSARDataset(SentinelDataset):\n",
    "            def __getitem__(self, idx):\n",
    "                sar_img, _ = super().__getitem__(idx)\n",
    "                return sar_img, sar_img  # Return SAR as both input and target\n",
    "        \n",
    "        base_transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(config_module.config.data.img_size, scale=(0.2, 1.0), interpolation=3),\n",
    "            transforms.Resize((config_module.config.data.img_size, config_module.config.data.img_size)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ColorJitter(contrast=0.5),\n",
    "        ])\n",
    "        paired_transform = PairedTransform(base_transform)\n",
    "        \n",
    "        train_dataset = SARtoSARDataset(\n",
    "            data_path=config_module.config.data.train_data,\n",
    "            transform=paired_transform\n",
    "        )\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=config_module.config.train.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=config_module.config.data.num_workers,\n",
    "            drop_last=True\n",
    "        )\n",
    "    \n",
    "    # Handle greyscale conversion (Experiment 4)\n",
    "    elif exp_name == 'exp4_grey_sar_to_grey':\n",
    "        from data.dataset_sentinel import SentinelDataset\n",
    "        from data.data_pretrain import PairedTransform\n",
    "        from torchvision import transforms\n",
    "        from torch.utils.data import DataLoader\n",
    "        \n",
    "        class GreyscaleOpticalDataset(SentinelDataset):\n",
    "            def __getitem__(self, idx):\n",
    "                sar_img, opt_img = super().__getitem__(idx)\n",
    "                # Convert optical to greyscale (weighted average)\n",
    "                grey_img = 0.299 * opt_img[0:1] + 0.587 * opt_img[1:2] + 0.114 * opt_img[2:3]\n",
    "                grey_img = grey_img.repeat(3, 1, 1)  # Repeat to 3 channels\n",
    "                return sar_img, grey_img\n",
    "        \n",
    "        base_transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(config_module.config.data.img_size, scale=(0.2, 1.0), interpolation=3),\n",
    "            transforms.Resize((config_module.config.data.img_size, config_module.config.data.img_size)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ColorJitter(contrast=0.5),\n",
    "        ])\n",
    "        paired_transform = PairedTransform(base_transform)\n",
    "        \n",
    "        train_dataset = GreyscaleOpticalDataset(\n",
    "            data_path=config_module.config.data.train_data,\n",
    "            transform=paired_transform\n",
    "        )\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=config_module.config.train.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=config_module.config.data.num_workers,\n",
    "            drop_last=True\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        # Standard data loader for MGF and RGB experiments\n",
    "        train_loader = build_loader(dataset_name='sentinel')\n",
    "    \n",
    "    print(f\"  Dataset size: {len(train_loader.dataset)}\")\n",
    "    print(f\"  Batch size: {config_module.config.train.batch_size}\")\n",
    "    print(f\"  Number of batches: {len(train_loader)}\")\n",
    "    \n",
    "    # Create model\n",
    "    print(\"\\nInitializing model...\")\n",
    "    model = SARATRX(\n",
    "        img_size=config_module.config.data.img_size,\n",
    "        in_chans=config_module.config.model.in_chans,\n",
    "        mgf_kens=config_module.config.model.mgf_kens,\n",
    "        target_mode=config_module.config.model.target_mode,\n",
    "        norm_pix_loss=config_module.config.model.norm_pix_loss\n",
    "    )\n",
    "    \n",
    "    # Setup checkpointing to Google Drive\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=os.path.join(checkpoint_dir, exp_name),\n",
    "        filename='epoch{epoch:02d}-loss{train_loss:.4f}',\n",
    "        monitor='train_loss',\n",
    "        mode='min',\n",
    "        save_top_k=3,\n",
    "        save_last=True,\n",
    "        every_n_epochs=5,  # Save every 5 epochs\n",
    "        auto_insert_metric_name=False\n",
    "    )\n",
    "    \n",
    "    # Setup logging\n",
    "    logger = TensorBoardLogger(\n",
    "        save_dir=log_dir,\n",
    "        name=exp_name\n",
    "    )\n",
    "    \n",
    "    # Create trainer\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=config_module.config.train.epochs,\n",
    "        accelerator='auto',\n",
    "        devices=1,\n",
    "        precision='16-mixed',  # Mixed precision for T4 GPU\n",
    "        gradient_clip_val=config_module.config.train.clip_grad,\n",
    "        callbacks=[checkpoint_callback],\n",
    "        logger=logger,\n",
    "        log_every_n_steps=10,\n",
    "        enable_progress_bar=True\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    print(\"\\nStarting training...\")\n",
    "    trainer.fit(model, train_loader)\n",
    "    \n",
    "    print(f\"\\n✓ Experiment {exp_name} completed!\")\n",
    "    print(f\"  Checkpoints saved to: {os.path.join(checkpoint_dir, exp_name)}\")\n",
    "    print(f\"  Logs saved to: {os.path.join(log_dir, exp_name)}\")\n",
    "    \n",
    "    return exp_name\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import argparse\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--config', type=str, required=True, help='Path to config file')\n",
    "    parser.add_argument('--checkpoint_dir', type=str, default='/content/drive/MyDrive/SARATRX_experiments/checkpoints')\n",
    "    parser.add_argument('--log_dir', type=str, default='/content/drive/MyDrive/SARATRX_experiments/logs')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    train_experiment(args.config, args.checkpoint_dir, args.log_dir)\n",
    "\n",
    "print(\"✓ Training script created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run-experiments"
   },
   "source": [
    "## 11. Run Training Experiments\n",
    "\n",
    "Now we'll run each experiment sequentially. Each experiment will:\n",
    "- Train for 50 epochs (reduced for T4 GPU constraints)\n",
    "- Save checkpoints every 5 epochs to Google Drive\n",
    "- Log training metrics to TensorBoard\n",
    "\n",
    "**Note**: Due to the 1.5 hour free tier limit, you may need to run experiments across multiple sessions. Checkpoints are saved to Google Drive and persist after the session ends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exp1"
   },
   "source": [
    "### Experiment 1: Pixel-Reconstruction (SAR → SAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run-exp1"
   },
   "outputs": [],
   "source": [
    "!python train_experiments.py \\\n",
    "    --config config/experiments/exp1_pixel_sar.yaml \\\n",
    "    --checkpoint_dir /content/drive/MyDrive/SARATRX_experiments/checkpoints \\\n",
    "    --log_dir /content/drive/MyDrive/SARATRX_experiments/logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exp2"
   },
   "source": [
    "### Experiment 2: MGF-Reconstruction (SAR → Multi-scale Gradient Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run-exp2"
   },
   "outputs": [],
   "source": [
    "!python train_experiments.py \\\n",
    "    --config config/experiments/exp2_mgf_sar.yaml \\\n",
    "    --checkpoint_dir /content/drive/MyDrive/SARATRX_experiments/checkpoints \\\n",
    "    --log_dir /content/drive/MyDrive/SARATRX_experiments/logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exp3"
   },
   "source": [
    "### Experiment 3: RGB-Reconstruction (SAR → RGB Optical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run-exp3"
   },
   "outputs": [],
   "source": [
    "!python train_experiments.py \\\n",
    "    --config config/experiments/exp3_rgb_sar_to_rgb.yaml \\\n",
    "    --checkpoint_dir /content/drive/MyDrive/SARATRX_experiments/checkpoints \\\n",
    "    --log_dir /content/drive/MyDrive/SARATRX_experiments/logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exp4"
   },
   "source": [
    "### Experiment 4: Greyscale-Reconstruction (SAR → Greyscale Optical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run-exp4"
   },
   "outputs": [],
   "source": [
    "!python train_experiments.py \\\n",
    "    --config config/experiments/exp4_grey_sar_to_grey.yaml \\\n",
    "    --checkpoint_dir /content/drive/MyDrive/SARATRX_experiments/checkpoints \\\n",
    "    --log_dir /content/drive/MyDrive/SARATRX_experiments/logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "monitor"
   },
   "source": [
    "## 12. Monitor Training with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tensorboard"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /content/drive/MyDrive/SARATRX_experiments/logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "results"
   },
   "source": [
    "## 13. View Experiment Results\n",
    "\n",
    "After training, checkpoints and logs are saved to:\n",
    "```\n",
    "/content/drive/MyDrive/SARATRX_experiments/\n",
    "├── checkpoints/\n",
    "│   ├── exp1_pixel_sar/\n",
    "│   ├── exp2_mgf_sar/\n",
    "│   ├── exp3_rgb_sar_to_rgb/\n",
    "│   └── exp4_grey_sar_to_grey/\n",
    "└── logs/\n",
    "    ├── exp1_pixel_sar/\n",
    "    ├── exp2_mgf_sar/\n",
    "    ├── exp3_rgb_sar_to_rgb/\n",
    "    └── exp4_grey_sar_to_grey/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check-results"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "checkpoint_dir = '/content/drive/MyDrive/SARATRX_experiments/checkpoints'\n",
    "\n",
    "print(\"Experiment Results:\\n\")\n",
    "for exp in ['exp1_pixel_sar', 'exp2_mgf_sar', 'exp3_rgb_sar_to_rgb', 'exp4_grey_sar_to_grey']:\n",
    "    exp_path = os.path.join(checkpoint_dir, exp)\n",
    "    if os.path.exists(exp_path):\n",
    "        ckpt_files = [f for f in os.listdir(exp_path) if f.endswith('.ckpt')]\n",
    "        print(f\"✓ {exp}:\")\n",
    "        print(f\"  Checkpoints: {len(ckpt_files)}\")\n",
    "        if ckpt_files:\n",
    "            for ckpt in sorted(ckpt_files)[-3:]:  # Show last 3\n",
    "                size_mb = os.path.getsize(os.path.join(exp_path, ckpt)) / (1024*1024)\n",
    "                print(f\"    - {ckpt} ({size_mb:.1f} MB)\")\n",
    "    else:\n",
    "        print(f\"✗ {exp}: Not started\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "resume"
   },
   "source": [
    "## 14. Resume Training (if session expires)\n",
    "\n",
    "If your Colab session expires before training completes, you can resume from the last checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "resume-training"
   },
   "outputs": [],
   "source": [
    "# To resume training from a checkpoint, modify the experiment config:\n",
    "import yaml\n",
    "\n",
    "# Example: Resume experiment 1\n",
    "exp_name = 'exp1_pixel_sar'\n",
    "config_path = f'config/experiments/{exp_name}.yaml'\n",
    "checkpoint_path = f'/content/drive/MyDrive/SARATRX_experiments/checkpoints/{exp_name}/last.ckpt'\n",
    "\n",
    "# Load config\n",
    "with open(config_path, 'r') as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "# Update resume path\n",
    "cfg['model']['resume'] = checkpoint_path\n",
    "\n",
    "# Save updated config\n",
    "with open(config_path, 'w') as f:\n",
    "    yaml.dump(cfg, f)\n",
    "\n",
    "print(f\"Updated config to resume from: {checkpoint_path}\")\n",
    "print(\"\\nNow run the experiment cell again to resume training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary"
   },
   "source": [
    "## Summary\n",
    "\n",
    "This notebook:\n",
    "1. ✓ Mounts Google Drive for persistent storage\n",
    "2. ✓ Clones SARATR-X repository\n",
    "3. ✓ Downloads Sentinel-1&2 dataset from Kaggle\n",
    "4. ✓ Converts images to NPY format\n",
    "5. ✓ Creates 4 experiment configurations:\n",
    "   - Pixel-reconstruction (SAR → SAR)\n",
    "   - MGF-reconstruction (SAR → MGF)\n",
    "   - RGB-reconstruction (SAR → RGB)\n",
    "   - Greyscale-reconstruction (SAR → Greyscale)\n",
    "6. ✓ Trains each experiment with:\n",
    "   - T4 GPU optimization (batch size 32, mixed precision)\n",
    "   - Regular checkpointing to Google Drive\n",
    "   - TensorBoard logging\n",
    "7. ✓ Handles session expiry with resume capability\n",
    "\n",
    "All results persist in Google Drive after session ends!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
